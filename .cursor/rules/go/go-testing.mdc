---
description: Go testing best practices following Google standards
globs: **/*.go
alwaysApply: false
---

# ðŸ§ª Go Testing Best Practices (Google Standards)

## Test Organization

- Place tests in the same package as the code being tested
- Use `*_test.go` files with descriptive names
- Group related tests using `t.Run()` for subtests
- Use table-driven tests for multiple test cases
- Keep test files focused and well-organized

## Test Structure and Naming

```go
// Test function names should be descriptive and follow the pattern:
// TestFunctionName_Scenario_ExpectedResult
func TestParseConfig_ValidXML_ReturnsConfig(t *testing.T) {
    tests := []struct {
        name     string
        input    string
        expected *Config
        wantErr  bool
    }{
        {
            name:     "valid xml config",
            input:    "<opnsense>...</opnsense>",
            expected: &Config{},
            wantErr:  false,
        },
        {
            name:     "invalid xml",
            input:    "<invalid>",
            expected: nil,
            wantErr:  true,
        },
    }

    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            result, err := ParseConfig(tt.input)
            if (err != nil) != tt.wantErr {
                t.Errorf("ParseConfig() error = %v, wantErr %v", err, tt.wantErr)
                return
            }
            if !reflect.DeepEqual(result, tt.expected) {
                t.Errorf("ParseConfig() = %v, want %v", result, tt.expected)
            }
        })
    }
}
```

## Test Coverage

- Aim for >80% test coverage
- Use `go test -cover` to measure coverage
- Use `go test -coverprofile=coverage.out` for detailed reports
- Focus on critical paths and error conditions
- Test both success and failure cases

## Benchmarking

```go
func BenchmarkParseConfig(b *testing.B) {
    input := "<opnsense>...</opnsense>"
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        _, err := ParseConfig(input)
        if err != nil {
            b.Fatal(err)
        }
    }
}
```

## Test Utilities and Helpers

- Create test helpers in `*_test.go` files
- Use `testing.TB` interface for shared helpers
- Create test fixtures and mock data
- Use `t.Helper()` for helper functions
- Keep helpers simple and focused

```go
func setupTestConfig(t *testing.T) *Config {
    t.Helper()
    return &Config{
        InputFile:  "testdata/config.xml",
        OutputFile: "testdata/output.md",
    }
}

func createTempFile(t *testing.T, content string) string {
    t.Helper()
    tmpfile, err := os.CreateTemp("", "test-*.xml")
    if err != nil {
        t.Fatal(err)
    }
    t.Cleanup(func() { os.Remove(tmpfile.Name()) })

    if _, err := tmpfile.Write([]byte(content)); err != nil {
        t.Fatal(err)
    }
    if err := tmpfile.Close(); err != nil {
        t.Fatal(err)
    }
    return tmpfile.Name()
}
```

## Integration Tests

- Use `//go:build integration` build tags
- Test component interactions
- Use real dependencies when possible
- Clean up test data after each test
- Use separate test databases or mock external services

```go
//go:build integration

package parser

func TestParseConfig_Integration(t *testing.T) {
    // Integration test implementation
}
```

## Error Testing

- Always test error conditions
- Verify error messages contain useful information
- Test both expected and unexpected errors
- Use `errors.Is()` and `errors.As()` for error checking
- Test error wrapping and context

```go
func TestParseConfig_InvalidInput_ReturnsError(t *testing.T) {
    _, err := ParseConfig("invalid xml")
    if err == nil {
        t.Fatal("expected error, got nil")
    }

    var parseErr *ParseError
    if !errors.As(err, &parseErr) {
        t.Errorf("expected ParseError, got %T", err)
    }

    if !strings.Contains(err.Error(), "invalid xml") {
        t.Errorf("error message should contain 'invalid xml', got: %s", err.Error())
    }
}
```

## Test Data Management

- Use constants for test data
- Create realistic test scenarios
- Avoid hardcoded magic numbers
- Use test fixtures for complex data structures
- Use `testdata/` directory for test files

## Test Performance

- Keep tests fast (<100ms per test)
- Use `testing.Short()` for expensive tests
- Parallelize tests when safe with `t.Parallel()`
- Avoid network calls in unit tests
- Use `b.ResetTimer()` in benchmarks

## Mocking and Stubbing

- Use interfaces for testability
- Create mock implementations for external dependencies
- Use `gomock` or similar tools for complex mocking
- Keep mocks simple and focused
- Test the contract, not the implementation

```go
type ConfigParser interface {
    Parse(data []byte) (*Config, error)
}

type mockParser struct {
    config *Config
    err    error
}

func (m *mockParser) Parse(data []byte) (*Config, error) {
    return m.config, m.err
}
```

## Test Documentation

- Write clear test descriptions
- Document test setup and teardown
- Explain complex test scenarios
- Use comments for non-obvious test logic
- Keep test names self-documenting

## Test Execution Commands

```bash
# Run all tests
go test ./...

# Run tests with coverage
go test -cover ./...

# Run tests with race detection
go test -race ./...

# Run only short tests
go test -short ./...

# Run benchmarks
go test -bench=. ./...

# Run integration tests
go test -tags=integration ./...

# Use just commands for consistent workflow
just test              # Run the full test suite
just ci-check          # Run CI-equivalent checks locally
```

## Test File Organization

- Group related tests together
- Use consistent test file naming
- Keep test files focused on a single package
- Use test helpers for common setup
- Separate unit tests from integration tests
